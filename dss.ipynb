{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d08156-eba7-4ce9-aff0-da779007a015",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c721090-05f0-4a6c-9f52-7c4493466026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading env variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411168cc-654e-4ba1-bd34-9a923bd58376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce9b16-a883-4ef5-a46e-c35a801eadd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running query over ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb18310-34f7-46b4-a38d-ee83c7c33cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing model\n",
    "llm = OpenAI(temperature=0)\n",
    "query = \"What is Langchain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9bfe5-577c-4256-9141-9b9b40a47dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "print(llm(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce5c6e-16d0-456e-a9af-f473561289e4",
   "metadata": {},
   "source": [
    "# Loading documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd272b-b180-4400-a9e3-b1ee0d3503fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the documentation\n",
    "loader = ReadTheDocsLoader(\"rtdocs\", features='html.parser')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09757d5-6aea-47b0-bf19-370d24c2517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the one document\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf006ab4-1e64-4432-b6b7-70895e6a4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs_splitted = text_splitter.split_documents(docs)\n",
    "print(len(docs_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bac1f-019f-4b1a-8b10-9aa29dd43eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplication\n",
    "docs_dic = {d.page_content: d for d in docs_splitted}\n",
    "len(docs_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95101285-e1eb-42af-8425-d463b00690ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistence in Vector DB\n",
    "import os\n",
    "persist_directory = 'db'\n",
    "embeddings = OpenAIEmbeddings()\n",
    "if os.path.exists(persist_directory + \"/index\"):\n",
    "    print(\"Loading Chroma DB\")\n",
    "    vectorstore = Chroma(embedding_function=embeddings, persist_directory=persist_directory)\n",
    "else:\n",
    "    print(\"Creating Chroma DB\")\n",
    "    vectorstore = Chroma.from_documents(docs_dic.values(), embeddings, persist_directory=persist_directory)\n",
    "    vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05b334-7812-4c03-b801-05a8f0019195",
   "metadata": {},
   "source": [
    "# Querying documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0eb14-8749-4b98-8c01-40f386eca14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query docs\n",
    "docs = vectorstore.as_retriever().get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5524d-73a2-434b-8808-8293c7097ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answer\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd21d5-0828-4a12-bfd1-a09b807f8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same but simpler\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c493a5-54be-444e-b34c-9535753f2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next query\n",
    "query2 = \"What is chain?\"\n",
    "qa(query2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dss",
   "language": "python",
   "name": "dss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
